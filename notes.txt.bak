# To initialise and use ollama in python..

!pip install ollama

import ollama

model = 'qwen2:0.5b-instruct'

input_prompt = input("Enter your prompt: ")

response_stream = ollama.chat(model = model, 
							  messages = [
								{
									'role':'user',
									'content':input_prompt,
								
								}],
								stream = True,
								)
# This may not output as expected
for chunk in stream:
	output = f"{chunk['message']['content'], end = '', flush = True}"
	

# To get embeddings
ollama.embeddings(model=model, prompt='The sky is blue because of rayleigh scattering')
